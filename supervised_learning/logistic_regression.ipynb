{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69756bc4-09ce-45df-a6a0-7fdfbea1f5c8",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cb23f1-f8d5-4e83-b3d6-24133316cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb001cd-c490-4941-985b-c8a9370398dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dataset():\n",
    "    # Iris dataset.\n",
    "    iris = datasets.load_iris()     # Load Iris dataset.\n",
    "\n",
    "    X = iris.data                   # The shape of X is (150, 4), which means\n",
    "                                    # there are 150 data points, each data point\n",
    "                                    # has 4 features.\n",
    "\n",
    "    # Here for convenience, we divide the 3 kinds of flowers into 2 groups: \n",
    "    #     Y = 0 (or False):  Setosa (original value 0) / Versicolor (original value 1)\n",
    "    #     Y = 1 (or True):   Virginica (original value 2)\n",
    "\n",
    "    # Thus use (iris.target > 1.5) to divide the targets into 2 groups. \n",
    "    # This line of code will assign:\n",
    "    #    Y[i] = True  (which is equivalent to 1) if iris.target[k]  > 1.5 (Virginica)\n",
    "    #    Y[i] = False (which is equivalent to 0) if iris.target[k] <= 1.5 (Setosa / Versicolor)\n",
    "\n",
    "    Y = (iris.target > 1.5).reshape(-1,1).astype(float) # The shape of Y is (150, 1), which means \n",
    "                                    # there are 150 data points, each data point\n",
    "                                    # has 1 target value. \n",
    "    Y[Y==0] = -1\n",
    "\n",
    "    X_and_Y = np.hstack((X, Y))     # Stack them together for shuffling.\n",
    "    np.random.seed(1)               # Set the random seed.\n",
    "    np.random.shuffle(X_and_Y)      # Shuffle the data points in X_and_Y array\n",
    "\n",
    "    print(\"X.shape\", X.shape)\n",
    "    print(\"Y.shape\", Y.shape)\n",
    "    print(\"X_and_Y[0]\", X_and_Y[0])  # The result should be always: [ 5.8  4.   1.2  0.2  0. ]\n",
    "\n",
    "    # Divide the data points into training set and test set.\n",
    "    X_shuffled = X_and_Y[:,:4]\n",
    "    Y_shuffled = X_and_Y[:,4]\n",
    "\n",
    "\n",
    "    X_train = X_shuffled[:100][:,[3,1]] # Shape: (100,2)\n",
    "    X_train = np.delete(X_train, 42, axis=0) # Remove a point for separability.\n",
    "    Y_train = Y_shuffled[:100]          # Shape: (100,)\n",
    "    Y_train = np.delete(Y_train, 42, axis=0) # Remove a point for separability.\n",
    "    X_test = X_shuffled[100:][:,[3,1]]  # Shape: (50,2)\n",
    "    Y_test = Y_shuffled[100:]           # Shape: (50,)\n",
    "    print(\"X_train.shape\", X_train.shape)\n",
    "    print(\"Y_train.shape\", Y_train.shape)\n",
    "    print(\"X_test.shape\", X_test.shape)\n",
    "    print(\"Y_test.shape\", Y_test.shape)\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = construct_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc2ea2e-12d2-4235-91e8-993a488c1f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis(X, Y, W=None, b=None):\n",
    "    indices_neg1 = (Y == -1).nonzero()[0]\n",
    "    indices_pos1 = (Y == 1).nonzero()[0]\n",
    "    plt.scatter(X[:,0][indices_neg1], X[:,1][indices_neg1], \n",
    "                c='blue', label='class -1')\n",
    "    plt.scatter(X[:,0][indices_pos1], X[:,1][indices_pos1], \n",
    "                c='red', label='class 1')\n",
    "    plt.legend()\n",
    "    plt.xlabel('$x_0$')\n",
    "    plt.ylabel('$x_1$')\n",
    "    \n",
    "    if W is not None:\n",
    "        # w0x0+w1x1+b=0 => x1=-w0x0/w1-b/w1\n",
    "        w0 = W[0]\n",
    "        w1 = W[1]\n",
    "        temp = -w1*np.array([X[:,1].min(), X[:,1].max()])/w0-b/w0\n",
    "        x0_min = max(temp.min(), X[:,0].min())\n",
    "        x0_max = min(temp.max(), X[:,1].max())\n",
    "        x0 = np.linspace(x0_min,x0_max,100)\n",
    "        x1 = -w0*x0/w1-b/w1\n",
    "        plt.plot(x0,x1,color='black')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc745563-eae5-44fd-a75a-1f7cbf4ee0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba7de9b-b133-4f71-9c0e-291b5d60a777",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724a5778-7062-4e85-85f4-229c5bb0f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function: sigmoid(z) = 1/(1 + e^(-z))\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c22fd40-e073-4ec0-97ec-6d1f48fadbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Judge function: 1(a != b).\n",
    "def judge(a, b):\n",
    "    \"\"\"\n",
    "    Judge function: 1(a != b).\n",
    "    Return 1 if a != b, otherwise return 0.\n",
    "    \"\"\"\n",
    "    if a != b:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def f_logistic(x, W, b):\n",
    "    \"\"\"\n",
    "    Logistic classifier: f(x, W, b)\n",
    "    This function should return -1 or 1.\n",
    "\n",
    "    x should be a 2-dimensional vector, \n",
    "    W should be a 2-dimensional vector,\n",
    "    b should be a scalar.\n",
    "    \"\"\"\n",
    "    z = np.dot(W, x) + b # calc value of z = linear combo \n",
    "    if sigmoid(z) >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "# Calculate error given feature vectors X and labels Y.\n",
    "def calc_error(X, Y, W, b):\n",
    "    e = 0\n",
    "    n = len(Y)\n",
    "    for (xi, yi) in zip(X, Y):\n",
    "        prediction_value = f_logistic(xi, W, b)\n",
    "        e = e + judge(yi, prediction_value)\n",
    "    \n",
    "    e = e/n\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4302e1d-08c3-42d0-9f5b-3f3ee10b1b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient of L(W, b) with respect to W and b.\n",
    "def grad_L_W_b(X, Y, W, b):\n",
    "    z = X @ W + b\n",
    "    prob = sigmoid(-Y * z)\n",
    "\n",
    "    grad_W = -(Y * prob) @ X # grad with respect to W\n",
    "    grad_b = -np.sum(Y * prob) # grad with respect to b\n",
    "                                \n",
    "    return grad_W, grad_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adae7ab-887e-4dd1-ab8f-f1727fa364d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss L(W, b).\n",
    "def L_W_b(X, Y, W, b):\n",
    "    z = X @ W + b\n",
    "    output = -Y * z\n",
    "    loss = np.sum(np.log(1 + np.exp(output)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bcc572-198a-40f3-a48a-4e26ae200d25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
